{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "Autoencoders are artificial neural networks capable of learning efficient representations of the input data, called codings, without supervision (i.e. training set is unlabeled). The advantages of autoencoders are:\n",
    "\n",
    "- Dimensionality reduction\n",
    "- Feature detection\n",
    "- New data generation\n",
    "\n",
    "The internal representation of the autoencoder has a lower dimensionality than the input data hence the autoencoder is said to be *undercomplete*. An undercomplete autoencoder cannot trivially output its inputs to the codings, yet it must find a way to output a copy of its inputs. It is forced to learn the most important features in the input data (and drop the unimportant ones).\n",
    "\n",
    "\n",
    "## Performing PCA with an Undercomplete Linear Autoencoder\n",
    "\n",
    "If the autoencoder uses only linear activation functions and the cost function is the MSE then it can be shown that it ends up performing Principal Component Analysis.\n",
    "\n",
    "The following code builds a simple linear autoencoder to perform PCA on a 3D dataset, projecting it to 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3 #3D inputs\n",
    "n_hidden = 2 #2D codings\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs])\n",
    "hidden = fully_connected(X, n_hidden, activation_fn = None)\n",
    "outputs = fully_connected(hidden, n_outputs, activation_fn = None)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #MSE\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(reconstruction_loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is similar the the MLP codes we have built in past training books. Two things to note are:\n",
    "a) number of outputs equal number of inputs\n",
    "b) To perform PCA we set activation_fn = None and cost function MSE.\n",
    "\n",
    "Now let's look at the execution phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = [...] #load dataset\n",
    "\n",
    "n_iterations = 1000\n",
    "codings = hidden #the output of the hidden layer provides codings\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        training_op.run(feed_dict = {X: X_train}) #no labels {unsupervised}\n",
    "    codings_val = codings.eval(feed_dict = {X: X_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Autoencoders\n",
    "\n",
    "Similar to NN we can stack hidden layers to get more complex encodings for our autoencoder. The architecture of the stacked autoencoder is typically symmetrical with regards to the hidden layer. \n",
    "\n",
    "### TensorFlow Implementation\n",
    "\n",
    "Following code builds a stacked autoencoder for MNISt using He initialization, the ELU activation function and regularization. The only difference is there are no labels (no y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150 #codings\n",
    "n_hidden3 = 300\n",
    "n_outputs = n_inputs \n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs])\n",
    "with tf.contrib.framework.arg_scope(\n",
    "    [fully_connected],\n",
    "    activation_fn = tf.nn.elu,\n",
    "    weights_initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "    weights_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)):\n",
    "    hidden1 = fully_connected(X, n_hidden1)\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2) #codings\n",
    "    hidden3 = fully_connected(hidden2, n_hidden3)\n",
    "    outputs = fully_connected(hidden3, n_outputs, activation_fn = None)\n",
    "    \n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #MSe\n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then train the model normally. note that digit labels (y_batch are unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_inputs))\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict = {X: X_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tying Weights\n",
    "\n",
    "For symmetrical autoencoders we can tie the weights of the decoder and encoder layers thereby halving the number of weights for the model. This leads to a reduced risk of overfitting as well as speed boost.\n",
    "\n",
    "Implementing tied weights in TensorFlow using fully_connected() function is a bit cumbersome. We have to define the layers manually as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs])\n",
    "\n",
    "weights1_init = initializer([n_inputs, n_hidden1])\n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype = tf.float32, name = \"weights1\")\n",
    "weights2 = tf.Variable(weights2_init, dtype = tf.float32, name = \"weights2\")\n",
    "weights3 = tf.transpose(weights2, name = \"weights3\") #tied weights\n",
    "weights4 = tf.transpose(weights1, name = \"weights4\") #tied weights\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name = \"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name = \"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name = \"biases3\")\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name = \"biases4\")\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "output = tf.matmul(hidden3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "loss - reconstruction_loss + reg_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing to note about the code above:\n",
    "\n",
    "- weights3 and weights4 are not variables, they are respectively the transpose of weights2 and weights1 (they are \"tied\" to them).\n",
    "\n",
    "- Since they are not variables, it is no use regularizing them: we only regularize weights1 and weights2\n",
    "\n",
    "- Biases are never tied, and never regularized\n",
    "\n",
    "\n",
    "## Training One Autoencoder at a Time\n",
    "\n",
    "Training different components of a stacked autoencoder separately. \n",
    "\n",
    "The code looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[...] #Build the whole stacked autoencoder normally.\n",
    "      #In this example the weights are not tied\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "with tf.name_scope(\"phase1\"):\n",
    "    phase1_outputs = tf.matmul(hidden1, weights4) + biases4\n",
    "    phase1_reconstruction_loss = tf.reduce_mean(tf.square(phase1_outputs - X))\n",
    "    phase1_reg_loss = regularizer(weights1) + regularizer(weights4)\n",
    "    phase1_loss = phase1_reconstruction_loss + phase1_reg_loss\n",
    "    phase1_training_op = optimizer.minimize(phase1_loss)\n",
    "    \n",
    "with tf.name_scope(\"phase2\"):\n",
    "    phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden3 - hidden1))\n",
    "    phase2_reg_loss = regularizer(weights2) + regularizer(weights3)\n",
    "    phase2_loss = phase2_reconstruction_loss + phase2_reg_loss\n",
    "    train_vars = [weights2, biases2, weights3, biases3]\n",
    "    phase2_training_op = optimizer.minimize(phase2_loss, var_list = train_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first phase is rather straightforward: we just create an output layer that skips the hidden layers 2 and 3, then build the training operations to minimize the distance between the outputs and the inputs (plus some regularization).\n",
    "\n",
    "The second phase just adds operations needed to minimize the distance between the output of hidden layer 3 and hidden layer 1 (also with some regularization). Most importantly, we provide a list  of trainable variables to the minimize() method, making sure to leave out weights1 and biases1; this effectively freezes hidden layer 1 during phase 2.\n",
    "\n",
    "During the execution phase, all you need to do is run the phase 1 training op for number of epochs, then phase 2 training op for some more epochs.\n",
    "\n",
    "## Visualizing the Reconsutrctions\n",
    "\n",
    "One way to ensure that ana utoencoder is properly trained is to compare the inputs and outputs. They must be fairly similar and the differences should be unimportant details. lets plot two random digits and their reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_digits = 2\n",
    "X_test = mnist.test.images[:n_test_digits]\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    [...] #Train the Autoencoder\n",
    "    #Check: https://github.com/ageron/handson-ml/blob/master/15_autoencoders.ipynb\n",
    "    outputs.val = outputs.eval(feed_dict = {X: X_test})\n",
    "    \n",
    "    def plot_image(image, shape = [28,28]):\n",
    "        plt.imshow(image.reshape(shape), cmap = \"Greys\", interpolation = \"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "for digit_index in range(n_test_digits):\n",
    "    plt.subplot(n_test_digits, 2, digit_index*2 + 1)\n",
    "    plt_image(X_Test[digit_index])\n",
    "    plt.subplot(n_test_digits, 2 , digit_index * 2 + 2)\n",
    "    plot_image(outputs_val[digit_index])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Features\n",
    "\n",
    "For each neuron in the first hidden layer, you can create an image where pixel's intensity corresponds to the weight of the connection to the given neuron. For example, following code plots the features learned by five neurons in the first hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session as sess:\n",
    "    [...] #train autoencoder\n",
    "    weights1_val = weights1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.subplot(1,5, i + 1)\n",
    "    plot_image(weights1_val.T[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoders\n",
    "\n",
    "Autoencoders can be denoised (adding noise) in two ways. If we add a pure Gaussian noise to our inputs or if we randomly switch off some inputs similar to dropout.\n",
    "\n",
    "Following code is adding Gaussian noise to inputs. The method is similar to regular autoencoders, except you add noise to the inputs and reconstruction loss is calculated based on original inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs])\n",
    "X_noisy = X + tf.random_normal(tf.shape(X)) \n",
    "#using tf.shape(X) instead of X because X is only partially defined\n",
    "#during construction phase\n",
    "[...]\n",
    "hidden1 = activation(tf.matmul(X_noisy, weights1) + biases1)\n",
    "[...]\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #MSE\n",
    "[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the dropout version, which is more common, is also easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import dropout\n",
    "\n",
    "keep_prob = 0.7\n",
    "\n",
    "is_training = tf.placeholder_with_default(False, shape = (), name = 'is_training')\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_inputs])\n",
    "X_drop = dropout(X, kee_prob, is_training = is_training)\n",
    "[...]\n",
    "hidden1 = activation(tf.matmul(X_drop, weights1) + biases1)\n",
    "[...]\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #MSE\n",
    "[...]\n",
    "\n",
    "#During training we must set is_training to True using feed_dict\n",
    "\n",
    "sess.run(training_op, feed_dict = {X:X_batch, is_training: True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Autoencoders\n",
    "\n",
    "By using appropriate loss function (KL divergence) along with a hyperparameter (sparsity_weight) on our cost function, we try and enforce only the most important neurons in coding layer to activate. The sparsity objective is manually set and there is a fine balance between making the model too sparse, and hence useless in predicting and not sparse enough thereby unable to take advantage of the sparse autoencoder's properties. \n",
    "\n",
    "The implementation of Sparse autonecoder is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p,q):\n",
    "    return p* tf.log(p/q) + (1-p)*tf.log(1-p)/(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "sparsity_target = 0.1\n",
    "sparsity_weight = 0.2\n",
    "\n",
    "[...] #Build a normal autoencoder (coding layer is hidden1 here)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "hidden1_mean = tf.reduce_mean(hidden1, axis = 0) #batch mean\n",
    "sparsity_loss = tf.reduce_sum(kl_divergence(sparsity_target, hidden1_mean))\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) #MSE\n",
    "loss = reconstruction_loss + sparsity_weight * sparsity_loss\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important detail is the fact that the activations of the coding layer must be between 0 and 1 (and not equal to 0 or 1), else KL divergence will return NaN. A simple solution is to use the logistic function for the coding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.nn.sigmoid(tf.matmul(X, weights1) + biases1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple trick to speed up convergence is using cross entropy as reconstruction loss instead of MSE. To use it, we need to normalize inputs to make them take on values from 0 to 1, and use the logistic activation function in the output layer so the outputs also take on values from 0 to 1. \n",
    "\n",
    "TensorFlow's sigmoid_cross_entropy_with_logits function takes care of efficiently applying the logistic (sigmoid) activation function to the outputs and computing cross entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[...]\n",
    "logits = (tf.matmul(hidden1, weights2) + biases2)\n",
    "outputs = tf.nn.sigmoid(logits)\n",
    "\n",
    "reconstruction_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels = X, logits = logits))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders\n",
    "\n",
    "Sampling codings after representing inputs using a gaussian distribution with mean $\\mu$ and std deviation $\\sigma$. The cost function optimizes over a reconstruction loss which tries to make input look as similar to output as possible and latent loss which tries to represents inputs as a gaussian distribution.\n",
    "\n",
    "The latent loss equation can be coded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10 #smoothing term to avoid computing log(0)\n",
    "latent_loss = 0.5*tf.reduce_sum(tf.square(hidden3_sigma + tf.square(hidden3_mean)\n",
    "                                         - 1 - tf.log(eps + tf.square(hidden3_sigma))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or more simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_loss = 0.5 + tf.reduce_sum(tf.exp(hidden3_gamma + tf.square(hidden3_mean) \n",
    "                                         - 1 - hidden3_gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe following code builds the variational autoencoder using $log(\\sigma^{2})$ variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 #for MNIST\n",
    "n_hidden1 = 500\n",
    "n_hidden2 = 500\n",
    "n_hidden3 = 20 #codings\n",
    "n_hidden4 = n_hidden2\n",
    "n_hidden5 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.contrib.framework.arg_scope(\n",
    "    [fully_connected],\n",
    "    activation_fn = tf.nn.elu,\n",
    "    weights_initializer = tf.contrib.layers.variance_scaling_initializer()):\n",
    "    X = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "    hidden1 = fully_connected(X, n_hidden1)\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2)\n",
    "    hidden3_mean = fully_connected(hidden2, n_hidden3, activation_fn = None)\n",
    "    hidden3_gamma = fully_connected(hidden2, n_hidden3, activation_fn = None)\n",
    "    hidden3_sigma = tf.exp(0.5*hidden3_gamma)\n",
    "    noise = tf.random_normal(tf.shape(hidden3_sigma), dtype = tf.float32)\n",
    "    hidden3 = hidden3_mean + hidden3_sigma*noise\n",
    "    hidden4 = fully_connected(hidden3, n_hidden4)\n",
    "    hidden5 = fully_connected(hidden4, n_hidden5)\n",
    "    logits = fully_connected(hidden5, n_outputs, activation_fn = None)\n",
    "    outputs = tf.sigmoid(logits)\n",
    "    \n",
    "reconstruction_loss = tf.reduce_sum(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(targets=X, logits = logits))\n",
    "\n",
    "latent_loss = 0.5*tf.reduce_sum(\n",
    "    tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - 1 - hidden3_gamma)\n",
    "\n",
    "cost = reconstruction_loss + latent_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Digits\n",
    "\n",
    "Using VAE to generate images that look like handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-e9ae068af23e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcoding_rnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_digits = 60\n",
    "n_epochs = 50\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for each in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict = {X: X_batch})\n",
    "            \n",
    "coding_rnd = np.random.normal(size = [n_digits, n_hidden3])\n",
    "outputs_val = outputs.eval(feed_dict = {hidden3: codings_rnd})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the \"handwritten\" digits produced by the autoencoder looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(n_digits):\n",
    "    plt.subplot(n_digits, 10, iteration + 1)\n",
    "    plot_image(output_val[iteration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
