{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNNs in TensorFlow\n",
    "\n",
    "First, let's implement a very simple RNN model, without using any of TensorFlow's RNN operations. We will create an RNN composed of a layer of five recurrent neurons using the tanh activation function. We will assume that the RNN runs over only two time steps, taking input vector of size 3 at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32,[None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape = [n_inputs, n_neurons],dtype = tf.float32))\n",
    "Wy = tf. Variable(tf.random_normal(shape = [n_neurons, n_neurons], dtype = tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype = tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network looks much like a two-layer feedforward neural network, with a few twists: first, the same weights and bias terms are shared by both layers, and second, we feed input at each layer, and we get outputs from each layer. \n",
    "\n",
    "To run the model, we need to feed it the inputs at both time steps like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini-batch:    instance 0, instance 1, instance 2, instance 3\n",
    "X0_batch = np.array([[0,1,2], [3,4,5], [6,7,8], [9,0,1]]) # t = 0\n",
    "X1_batch = np.array([[9,8,7], [0,0,0], [6,5,4],[3,2,1]]) # t = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0,Y1], feed_dict = {X0:X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mini-batch contains four instances, each with an input sequence composed of the exactly two inputs. At the end, Y0_val and Y1_val contain the outputs of the network at both time steps for all neurons and all instances in the mini-batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9978484  -0.8388984  -0.9963468   0.99921966  0.9462805 ]\n",
      " [-1.         -0.42275447 -0.82361877  1.          0.9999997 ]\n",
      " [-1.          0.30530632  0.67278045  1.          1.        ]\n",
      " [-0.9472425   1.          1.         -0.89053035  1.        ]]\n",
      "[[-1.          0.9989584   1.          1.          1.        ]\n",
      " [-0.9976455  -0.00828366  0.9999609  -0.23960122 -0.9914078 ]\n",
      " [-1.          0.36997396  1.          1.          1.        ]\n",
      " [-0.99510556 -0.9900733   0.9999999   0.9999997   0.9999914 ]]\n"
     ]
    }
   ],
   "source": [
    "#output (4 mini batches (row) x 5 neurons (columns)) x 2 time steps (t=0,1)\n",
    "print(Y0_val) #output at t = 0\n",
    "print(Y1_val) #output at t = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Unrolling Through Time\n",
    "\n",
    "The static_rnn() (now replaced by tf.nn.rnn) function creates an unrolled RNN network by chaining cells. The following code creates the exact same code as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons)\n",
    "output_seqs , states = tf.nn.rnn(basic_cell, [X0,X1], \n",
    "                                 dtype = tf.float32)\n",
    "\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create input placeholders, as before. Then we create a BasicRNNCell, which you can think of as a factory that creates copies of the cell to build the unrolled RNN (one for each time step). \n",
    "\n",
    "Then we call nn.rnn(), giving the cell factory and the input tensors, and telling it the data type of inputs.\n",
    "\n",
    "The nn.rnn() function calls the cell factory's __call__() function once per input, creating two copies of the cell (each containing a layer of five recurrent neurons, which shared weights and bias terms, and it chains them just like we did earlier.\n",
    "\n",
    "The static_rnn() function returns two objects. The first is a Python list containing the output tensors for each step. The second is a tensor containing the final states of the network.\n",
    "\n",
    "When you are using basic cells, the final state is simply equal to the last output.\n",
    "\n",
    "------------------------\n",
    "------------------------\n",
    "Suppose, we have 50 time steps, it would be inconvenient to define 50 input placeholders and 50 output tensors. To simplify this the following code builds the same RNN again, but this time it takes a single input placeholder of shape [None, n_steps, n_inputs] where the first dimension is the mini-batch size.\n",
    "\n",
    "Then it extracts the list of input sequences for each time step. X_seqs is a python list of n_steps tensors of shape [None, n_inputs], where once again the first is the mini-batch size.\n",
    "\n",
    "To do this, we first swap the first two dimensions using the transpose() function, so that the time steps are now the first dimension. Then we extract a Python list of tensors along the first dimension (i.e. one tensor per time step) using the unstack () function.\n",
    "\n",
    "The next two lines are the same as before.\n",
    "\n",
    "Finally, we merge all the output tensors into a single tensor using the stack() function, and  we swap the first two dimensions to get the final outputs tensor of shape [None, n_steps, n_neurons](again first dimension is the mini-batch size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #stop getting reuse error\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm = [1,0,2]))\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons)\n",
    "\n",
    "output_seqs, states = tf.nn.rnn(basic_cell, X_seqs, dtype = tf.float32)\n",
    "\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm = [1,0,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the network by feeding it a single tensor that contains all the mini-batch sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    [[0,1,2],[9,6,7]], #instance 0\n",
    "    [[3,4,5], [0,0,0]], #instance 1\n",
    "    [[6,7,8], [6,5,4]], #instance 2\n",
    "    [[9,0,1], [3,2,1]], #instance 3\n",
    "])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict = {X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.85013986  0.22620182  0.09570671  0.01165123  0.41765642]\n",
      "  [ 0.99999917  0.92645323  0.5786223   0.8990805   0.9251097 ]]\n",
      "\n",
      " [[ 0.99981105  0.8789149   0.2906526   0.49308833  0.89505   ]\n",
      "  [-0.6515364  -0.7587294   0.8698612  -0.672047   -0.8924125 ]]\n",
      "\n",
      " [[ 0.99999964  0.9869238   0.46412593  0.78893834  0.9851777 ]\n",
      "  [ 0.99985224  0.74896526  0.9554794   0.1372736  -0.00246042]]\n",
      "\n",
      " [[ 0.9916968  -0.25550136 -0.6158796   0.99162024  0.6474958 ]\n",
      "  [ 0.9407799   0.8512076   0.384363   -0.47657797 -0.6362606 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Unrolling Through Time\n",
    "\n",
    "The dynamic_rnn() function uses a while_loop() operation to run over the cell the appropriate number of times, and you can set swap_memory = True if you want it to swap the GPU's memory to CPU during backprop to avoid OOM errors.\n",
    "\n",
    "Conveniently, it also accepts a single tensor for all inputs at every time step(shape[None, n_steps, n_inputs]) and it outputs a single tensor for all outputs at every time step (shape[None, n_steps, n_neurons]);\n",
    "\n",
    "There is no need to stack, unstack or transpose. The following code creates the same RNN as earlier using the dynamic_rnn() function much niver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_steps = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Variable Length Input Sequences\n",
    "\n",
    "So far we have used only fixed size input sequences (all exactly two steps long). What if the input sequences have variable lengths (eg, like sentences)? In this case you should set the sequence_length parameter when calling the dynamic_rnn() (or static_rnn()) function it must be a 1D tensor indicating the length of the input sequence for each instance. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "#----same as before----\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons)\n",
    "#----------------------\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, \n",
    "                                    dtype = tf.float32, \n",
    "                                   sequence_length = seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose the second input sequence contains only one input instead of two. It must be padded with zero vector in order to fit in the input tensor x(because the input tensor,s second dimension is the size of the longest sequence - i.e. 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    #step 0   step 1\n",
    "    [[0,1,2],[9,8,7]], #instance 0\n",
    "    [[3,4,5],[0,0,0]], #instance 1 (padded with zero vector)\n",
    "    [[6,7,8],[6,5,4]], #instance 2\n",
    "    [[9,0,1], [3,2,1]], #instacne 3    \n",
    "])\n",
    "\n",
    "seq_length_batch = np.array([2,1,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of couse, you now need to feed values for both placeholders x and seq_length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    output_val, states_val = sess.run(\n",
    "        [outputs, states], feed_dict = {X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the RNN outputs zero vectors for every time step past the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.7481924  -0.41833863 -0.865391    0.67262447  0.51136667]\n",
      "  [ 0.42523554 -0.93336535 -0.936078   -0.6782177   0.9999345 ]]\n",
      "\n",
      " [[ 0.8977136  -0.76589394 -0.9768165   0.6474266   0.9889001 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.96045864 -0.91781133 -0.99619526  0.62072885  0.99980736]\n",
      "  [-0.11894488 -0.94140685 -0.5675743  -0.49118972  0.9960541 ]]\n",
      "\n",
      " [[-0.999943   -0.96134156  0.9994977  -0.99759614  0.9962898 ]\n",
      "  [-0.6357697  -0.85447615  0.8104649  -0.26680082  0.95177114]]]\n"
     ]
    }
   ],
   "source": [
    "print(output_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, the states tensor contains the final state of each cell (excluding the zero vectors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42523554 -0.93336535 -0.936078   -0.6782177   0.9999345 ]\n",
      " [ 0.8977136  -0.76589394 -0.9768165   0.6474266   0.9889001 ]\n",
      " [-0.11894488 -0.94140685 -0.5675743  -0.49118972  0.9960541 ]\n",
      " [-0.6357697  -0.85447615  0.8104649  -0.26680082  0.95177114]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training RNNs\n",
    "\n",
    "To train RNN, the trick is to unroll it through time (like we did above) and then simply use regular backpropogation. This strategy is called backpropogation through time. \n",
    "\n",
    "Moreover since the same parameters W and b are used at each time step, backpropogation will do the right thing and sum over all time steps.\n",
    "\n",
    "## Training a Sequence Classifier\n",
    "\n",
    "Lets train an RNN to classify MNIST images. We will train each image as a sequence of 28 rows and 28 pixels each (since each MNIST image is 28 x 28 pixels). We will sue cells of 150 recurrent neurons plus a fully connected layer containing 10 neurons (one per class) connected to the output of the last time step, followed by a softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #reset graphs\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32,[None])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype = tf.float32)\n",
    "\n",
    "logits = fully_connected(states, n_outputs, activation_fn = None)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,\n",
    "                                                         logits = logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load the MNIST data and reshape the test data to [batch_size, n_steps, n_onputs] as is expected by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train the RNN. We reshape each training batch before feeding it to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy 0.98 Test accuracy: 0.884\n",
      "1 Train accuracy 0.94666666 Test accuracy: 0.9503\n",
      "2 Train accuracy 0.97333336 Test accuracy: 0.9556\n",
      "3 Train accuracy 0.94666666 Test accuracy: 0.9573\n",
      "4 Train accuracy 0.97333336 Test accuracy: 0.9596\n",
      "5 Train accuracy 0.9866667 Test accuracy: 0.9672\n",
      "6 Train accuracy 0.96666664 Test accuracy: 0.9696\n",
      "7 Train accuracy 0.97333336 Test accuracy: 0.964\n",
      "8 Train accuracy 0.97333336 Test accuracy: 0.9689\n",
      "9 Train accuracy 0.96666664 Test accuracy: 0.9757\n",
      "10 Train accuracy 0.98 Test accuracy: 0.9727\n",
      "11 Train accuracy 0.98 Test accuracy: 0.9739\n",
      "12 Train accuracy 0.9866667 Test accuracy: 0.9736\n",
      "13 Train accuracy 0.96666664 Test accuracy: 0.9711\n",
      "14 Train accuracy 1.0 Test accuracy: 0.9763\n",
      "15 Train accuracy 1.0 Test accuracy: 0.9805\n",
      "16 Train accuracy 0.9866667 Test accuracy: 0.9734\n",
      "17 Train accuracy 1.0 Test accuracy: 0.9767\n",
      "18 Train accuracy 0.98 Test accuracy: 0.9716\n",
      "19 Train accuracy 0.96666664 Test accuracy: 0.9657\n",
      "20 Train accuracy 0.99333334 Test accuracy: 0.9749\n",
      "21 Train accuracy 0.9866667 Test accuracy: 0.9763\n",
      "22 Train accuracy 1.0 Test accuracy: 0.9757\n",
      "23 Train accuracy 1.0 Test accuracy: 0.9771\n",
      "24 Train accuracy 0.99333334 Test accuracy: 0.9758\n",
      "25 Train accuracy 0.99333334 Test accuracy: 0.9766\n",
      "26 Train accuracy 0.98 Test accuracy: 0.9708\n",
      "27 Train accuracy 0.9866667 Test accuracy: 0.9776\n",
      "28 Train accuracy 1.0 Test accuracy: 0.9778\n",
      "29 Train accuracy 0.99333334 Test accuracy: 0.9739\n",
      "30 Train accuracy 1.0 Test accuracy: 0.9784\n",
      "31 Train accuracy 0.98 Test accuracy: 0.9755\n",
      "32 Train accuracy 0.99333334 Test accuracy: 0.9737\n",
      "33 Train accuracy 0.99333334 Test accuracy: 0.974\n",
      "34 Train accuracy 0.98 Test accuracy: 0.9728\n",
      "35 Train accuracy 1.0 Test accuracy: 0.9792\n",
      "36 Train accuracy 1.0 Test accuracy: 0.9758\n",
      "37 Train accuracy 0.98 Test accuracy: 0.9783\n",
      "38 Train accuracy 0.99333334 Test accuracy: 0.975\n",
      "39 Train accuracy 0.99333334 Test accuracy: 0.9753\n",
      "40 Train accuracy 1.0 Test accuracy: 0.9799\n",
      "41 Train accuracy 1.0 Test accuracy: 0.9713\n",
      "42 Train accuracy 0.98 Test accuracy: 0.9768\n",
      "43 Train accuracy 0.9866667 Test accuracy: 0.9774\n",
      "44 Train accuracy 1.0 Test accuracy: 0.9743\n",
      "45 Train accuracy 1.0 Test accuracy: 0.976\n",
      "46 Train accuracy 0.98 Test accuracy: 0.9685\n",
      "47 Train accuracy 0.9866667 Test accuracy: 0.9767\n",
      "48 Train accuracy 1.0 Test accuracy: 0.9751\n",
      "49 Train accuracy 0.99333334 Test accuracy: 0.9765\n",
      "50 Train accuracy 0.98 Test accuracy: 0.9763\n",
      "51 Train accuracy 0.9866667 Test accuracy: 0.9763\n",
      "52 Train accuracy 1.0 Test accuracy: 0.9778\n",
      "53 Train accuracy 1.0 Test accuracy: 0.9773\n",
      "54 Train accuracy 0.98 Test accuracy: 0.9751\n",
      "55 Train accuracy 0.9866667 Test accuracy: 0.976\n",
      "56 Train accuracy 0.99333334 Test accuracy: 0.9784\n",
      "57 Train accuracy 0.9866667 Test accuracy: 0.9765\n",
      "58 Train accuracy 0.99333334 Test accuracy: 0.9784\n",
      "59 Train accuracy 0.99333334 Test accuracy: 0.9723\n",
      "60 Train accuracy 0.99333334 Test accuracy: 0.9725\n",
      "61 Train accuracy 0.9866667 Test accuracy: 0.978\n",
      "62 Train accuracy 0.99333334 Test accuracy: 0.9804\n",
      "63 Train accuracy 0.99333334 Test accuracy: 0.9807\n",
      "64 Train accuracy 0.99333334 Test accuracy: 0.9767\n",
      "65 Train accuracy 0.99333334 Test accuracy: 0.9793\n",
      "66 Train accuracy 0.99333334 Test accuracy: 0.9756\n",
      "67 Train accuracy 0.99333334 Test accuracy: 0.9747\n",
      "68 Train accuracy 0.99333334 Test accuracy: 0.9786\n",
      "69 Train accuracy 0.99333334 Test accuracy: 0.973\n",
      "70 Train accuracy 0.9866667 Test accuracy: 0.9735\n",
      "71 Train accuracy 1.0 Test accuracy: 0.9768\n",
      "72 Train accuracy 0.9866667 Test accuracy: 0.9762\n",
      "73 Train accuracy 0.9866667 Test accuracy: 0.9785\n",
      "74 Train accuracy 0.99333334 Test accuracy: 0.9735\n",
      "75 Train accuracy 0.99333334 Test accuracy: 0.9798\n",
      "76 Train accuracy 1.0 Test accuracy: 0.9784\n",
      "77 Train accuracy 0.9866667 Test accuracy: 0.9752\n",
      "78 Train accuracy 0.99333334 Test accuracy: 0.9753\n",
      "79 Train accuracy 1.0 Test accuracy: 0.9793\n",
      "80 Train accuracy 1.0 Test accuracy: 0.9793\n",
      "81 Train accuracy 0.99333334 Test accuracy: 0.9767\n",
      "82 Train accuracy 0.99333334 Test accuracy: 0.9783\n",
      "83 Train accuracy 0.9866667 Test accuracy: 0.9776\n",
      "84 Train accuracy 0.99333334 Test accuracy: 0.977\n",
      "85 Train accuracy 0.9866667 Test accuracy: 0.9773\n",
      "86 Train accuracy 0.99333334 Test accuracy: 0.9707\n",
      "87 Train accuracy 1.0 Test accuracy: 0.9723\n",
      "88 Train accuracy 0.99333334 Test accuracy: 0.9748\n",
      "89 Train accuracy 1.0 Test accuracy: 0.9784\n",
      "90 Train accuracy 1.0 Test accuracy: 0.9783\n",
      "91 Train accuracy 0.98 Test accuracy: 0.9772\n",
      "92 Train accuracy 0.99333334 Test accuracy: 0.9681\n",
      "93 Train accuracy 0.99333334 Test accuracy: 0.9779\n",
      "94 Train accuracy 0.99333334 Test accuracy: 0.9801\n",
      "95 Train accuracy 1.0 Test accuracy: 0.9789\n",
      "96 Train accuracy 0.99333334 Test accuracy: 0.9762\n",
      "97 Train accuracy 1.0 Test accuracy: 0.9766\n",
      "98 Train accuracy 0.99333334 Test accuracy: 0.9788\n",
      "99 Train accuracy 0.99333334 Test accuracy: 0.9771\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict = {X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict = {X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict = {X:X_test, y:y_test})\n",
    "        print(epoch, \"Train accuracy\", acc_train, \"Test accuracy:\", acc_test)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training to Predict Time Series\n",
    "\n",
    "In this section we will train an RNN to predict the next value in a generated time series. Each trining instance is randomly selected sequence of 20 consecutive values from the time series, and the target sequence is the same as input sequence, except it is shifted by one time step into the future.\n",
    "\n",
    "First lets create the RNN. It will contain 100 recurrent neurons and we will unroll it over 20 time steps since each training instance will be 20 inputs long. Each input will contain only one feature (the value at that time). \n",
    "\n",
    "The targets are also sequence of 20 inputs, each containing a single value.\n",
    "\n",
    "### Construction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #reset graphs\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons, activation = tf.nn.relu)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each time step we now have an output vector of size 100. But what we want is a single output value of each time step. The simplest solution is to wrap the cell in an OutputProjectionWrapper. A cell wrapper acts like a normal cell, proxying every method call to an underlying cell, but it also adds some functionality. \n",
    "\n",
    "The OutputProjectionWrapper adds a fully connected layer of linear neurons (i.e. without any activation function) on top of each output (but it also does not affect the cell state). All these fully connected layers share the same (trainable) weights and bias terms.\n",
    "\n",
    "We will begin by wrapping the BasicRNNCell into an OutputProjectionWrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.OutputProjectionWrapper(\n",
    "    tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons, activation = tf.nn.relu),\n",
    "    output_size = n_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define cost function. We will use the MSE as we did in previous regression tasks. Next we will create an Adam optimizer, the training op, and the variable initialization op, as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 10000\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = [...] #fetch next training batch\n",
    "        sess.run(training_op, feed_dict = {X:X_batch, y: y_batch})\n",
    "        if iterations % 100 == 0:\n",
    "            mse = loss.eval(feed_dict = {X: X_batch, y: y_batch})\n",
    "            print(iterations, \"\\tmse\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, you can make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [...] #New sequences\n",
    "y_pred = sess.run(outputs, feed_dict = {X: X_new})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although using an OutputProjectionWrapper is the simplest solution to reduce the dimensionality of RNN's output sequence down to just one value per time step it is not the most efficient.\n",
    "\n",
    "You can reshape the RNN outputs from [batch_size, n_steps, n_neurons] to [batch_size x n_steps, n_neurons] then apply a single fully connected layer with appropriate output size, which will result in an output tensor of shape [batch_size x n_steps, n_outputs] and then rehsape this tensor to [batch_size, n_steps, n_outputs].\n",
    "\n",
    "To implement this solution, we first revert to a basic cell, without the OutputProjectionWrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons, activation = tf.nn.relu)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we stack all the outputs using the reshape() operation, apply the fully connected layer (without using any activation function; this is just a projection), and finally unstack all the outputs using reshape():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = fully_connected(stacked_rnn_outputs, n_outputs, activation_fn = None)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creative RNN\n",
    "\n",
    "Now that we ahve a model that can predict the future, we can use it to generate some creative sequences. All we need is to provide it a seed sequence containing n_step values (eg: full zeros), use the model to predict the next value, append this predicted value to the sequence, feed the last n_steps values to the model to predict next value, and so on. \n",
    "\n",
    "This process generates new sequences that has some resemblance to the original. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [0.]*n_steps #seed sequence that are n_steps long\n",
    "#print(sequence)\n",
    "for iteration in range(300):\n",
    "    X_batch = np.array(sequence[-n_steps:]).reshape(1, n_steps, 1)\n",
    "    y_pred = sess.run(outputs, feed_dict = {X: X_batch})\n",
    "    sequence.append(y_pred[0,-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep RNNs\n",
    "\n",
    "To implement a deep RNN in TensorFlow, you can create a several cells and stack them into a MultiRNNCell. In the following code we stack three identical cells (but you could use various kinds of cells with different number of neurons):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #reset graphs\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons)\n",
    "multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell([basic_cell]*n_layers)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The states variable is a tuple containing one tensor per layer, each representing the final state of that layer's cell (with shape[batch_size, n_neurons]). If you set state_is_tupe = False  when creating the MultiRNNCell, then states becomes a single tensor containing the states from every layer, concatenated along column axis (i.e., its shape is [batch_size, n_layers x n_neurons])\n",
    "\n",
    "\n",
    "## Applying Dropout\n",
    "\n",
    "You can simply add a dropout layer before or after the RNN as usual, but if you also want to apply dropout between the RNN layers, you need to use a DropoutWrapper.\n",
    "\n",
    "The following code applies dropout to the inputs of each layer in the RNN, dropping each input with a 50% probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #reset graphs\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "keep_prob = 0.5\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(num_units = n_neurons)\n",
    "cell_drop = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob = keep_prob)\n",
    "multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell([cell_drop]*n_layers)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem with this code is that it will apply dropout not only during training but also during testing, which is not what you want. Unfortunately, the DropoutWrapper does not support an is_training placeholder, so you must either write your own dropout wrapper class, or have two different graphs: one for training, and the other for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Cell\n",
    "\n",
    "One issue suffered by RNNs is that the memory of the first inputs gradually fades away. Indeed, due to the transformations that data goes through traversing an RNN, some information is lost at each time step. After a while, RNNs state contains virtually no trace of the first inputs. \n",
    "\n",
    "To solve this problem, various types of cells with long0term memory have been introduced which have greatly outperformed basic cells. The most popular among them is the LSTM cell.\n",
    "\n",
    "The LSTM performs better, training converge faster and it detects long-term dependencies in the data. To implement LSTM instead of basic RNN cell use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM cells manage two state vectors and for performance reasons they are kept separate by default. You can change this default behavior by setting state_is_tupe = False when creating BasicLSTMCell.\n",
    "\n",
    "### Peephole Connections\n",
    "\n",
    "Type of LSTM variant with extra connections called peephole connections where apart from the inputs $x_t$ and $h_t$ the long term state $c_{(t-1)}$ is added as an input to the controllers of the forget gate and input gate, and the current long term state $c_t$ is added as input to the controller of the output gate.\n",
    "\n",
    "To implement peephole connections in TensorFlow, you muse use the LSTMCell instead of the BasicLSTMCell and set use_peepholes = True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units = n_neurons, use_peepholes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Cell (Gated Recurrent Unit)\n",
    "\n",
    "Introduces encoder-decoder sequences to LSTM. Much simpler and works just as well with only 1 state vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_cell = tf.nn.rnn_cell.GRUCell(num_units = n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
