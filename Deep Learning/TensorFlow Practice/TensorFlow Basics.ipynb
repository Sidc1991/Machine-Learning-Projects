{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating First Tensorflow Graph\n",
    "\n",
    "In our first example, we create a tensorflow graph representing the formula:\n",
    "\n",
    "$$ f(x,y) = x^2y + y + 2 $$\n",
    "\n",
    "Where x = 3 and y = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name = \"x\")\n",
    "y = tf.Variable(4, name = \"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to note that the above code does not perform any computation. Only a computation graph is created.\n",
    "\n",
    "To evaluate the graph, we need to open a TensorFlow session and use it to initialize variables and evaluate f. Remember to close the session at the end to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more efficient way to re-write the above code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the with block the session is set as the default session. We no longer need to type sess.run everytime we initialize our variables. Moreover, session is automatically closed at the end of the block.\n",
    "\n",
    "Instead of manually running the initilizer for every single variable we can further simply the code using global_variables_initializer() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() #prepare an init node\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() #actually initialize all the variables\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid using the with block altogether and maintaining parsimony, we can use the InteractiveSession command. We do have to manually close session, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have introduced a new node x1 to default graph. \n",
    "\n",
    "If we want to manage graphs independent of each other, we can do so by created a new Graph and temporarily making it the default graph inside the with block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle of a Node Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is good at determining which nodes need to be evaluated first in case certain nodes require calculations from other nodes. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that it will not reuse the result of the previous evaluation of w and x. Instead, it evaluates w and x twice. \n",
    "\n",
    "All node values are dropped between graph runs. Variable values are kept across sessions, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with TensorFlow\n",
    "\n",
    "Linear regression formula:\n",
    "\n",
    "$\\theta = (X^T.X)^{-1}X^{T}y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "#print(housing)\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]\n",
    "#print(housing_data_plus_bias)\n",
    "#Building the computation graph\n",
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = \"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)), XT), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the computation graph\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent\n",
    "\n",
    "Very important to standardize before proceeding. (Can use commands like StandardScalar if it helps)\n",
    "\n",
    "### Manually Computing Gradients\n",
    "\n",
    "We start off by manually implementing batch gradient descent:\n",
    "\n",
    "$\\theta^{(next step)} = \\theta - \\eta\\Delta_{\\theta}MSE(\\theta) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE= 1008841.6\n",
      "Epoch 100 MSE= nan\n",
      "Epoch 200 MSE= nan\n",
      "Epoch 300 MSE= nan\n",
      "Epoch 400 MSE= nan\n",
      "Epoch 500 MSE= nan\n",
      "Epoch 600 MSE= nan\n",
      "Epoch 700 MSE= nan\n",
      "Epoch 800 MSE= nan\n",
      "Epoch 900 MSE= nan\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = \"y\")\n",
    "#random initialization of weights at the start between -1 and +1\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name = \"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = 2/m*tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate*gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "#Evaluate gradient descent\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE=\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Autodiff\n",
    "\n",
    "Here Tensorflow automatically determines how it should calculate the gradient in order to solve a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a,b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a*np.cos(z+i) + z*np.sin(b-i)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caclulate gradient descent with 1 line of code.\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients() function takes an op(in this case mse) and a list of variables(in this case just theta) and it creates a list of ops (one per variable) to compute the gradients of the op with regards to each variable using reverse-mode autodiff. Reverse mode auto-diff calculates the partial derivative of the outputs with regards to all inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding Data to the Training Algorithm\n",
    "\n",
    "We will now try to implement mini-batch gradient descent. The simplest way to do this is to use placeholder nodes. These nodes dont perform computation. They only output the data in mini-batch form at run time. \n",
    "\n",
    "To create a placeholder node, you must call placeholder() function and specify the output tensor's data type. In the following example, we create placeholder node A, and also node B = A + 5. \n",
    "\n",
    "When we evaluate B, we pass a feed_dict to the eval() method that specifies the value of A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]\n",
      " [15. 16. 17.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape = (None, 3)) #None for dimension implies any size\n",
    "#In A we can have any number of rows but 3 columns\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict = {A: [[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict = {A: [[4,5,6], [7,8,9], [10,11,12]]})\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement mini-batch gradient descent we need to change our input and output variables into placeholder nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = (None, n+1), name = \"x\")\n",
    "y = tf.placeholder(tf.float32, shape  = (None, 1), name = \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The define the batch size and compute total number of batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?np.ceil\n",
    "#np.ceil refers to the ceiling of each element in 'x'\n",
    "#Example\n",
    "#>>> a = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])\n",
    "#>>> np.ceil(a)\n",
    "#array([-1., -1., -0.,  1.,  2.,  2.,  2.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fetch mini-batches one by one, then provide the value of x and y via the feed_dict parameter when evaluating the node that depends on either of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def fetch_batch(epoch, batch_index, batch_size):\n",
    "    #load data from disk\n",
    "#    return X_batch, y_batch\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run(init)\n",
    "    \n",
    "#    for epoch in range(n_epochs):\n",
    "#        for batch_index in range(n_batches):\n",
    "#            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "#            sess.run(training_op, feed_dict = {X: X_batch, y:y_batch})\n",
    "            \n",
    "#        best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring Models\n",
    "\n",
    "After training the models, we want to save the parameters to disk so we can return to it whenever we want or use it in another program/compare models etc. We would also like to create checkpoints in case of computer crash.\n",
    "\n",
    "We will achieve this by creating the Saver node at the end of construction phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9681423 ]\n",
      " [ 0.4930575 ]\n",
      " [ 0.4602003 ]\n",
      " [-0.09579325]\n",
      " [ 0.39398646]\n",
      " [ 0.3718593 ]\n",
      " [ 0.03154683]\n",
      " [-0.8800242 ]\n",
      " [ 0.7732265 ]]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/siddharth/Desktop/TensorFlow/tmp/')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0,1.0), name = \"theta\")\n",
    "init = tf.global_variables_initializer()\n",
    "#saver node\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0: #checkpoint every 100 epochs\n",
    "            save_path = saver.save(sess,\"⁨my_model.ckpt\")\n",
    "            \n",
    "            sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    #print(best_theta)\n",
    "    save_path = saver.save(sess, \"⁨my_model_final.ckpt\")\n",
    "\n",
    "\n",
    "#For some reason the damn saver.save refused to take the full path.\n",
    "#Had to import os and then redefine the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/siddharth/Desktop/TensorFlow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restoring a model is just as easy. At the beginning of the execution phase, instead of initializing variables using the init node, you call the restore() method of the saver object.\n",
    "\n",
    "#### (Needs better code. Book not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/Users/siddharth/Desktop/TensorFlow/tmp/')\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    saver.restore(sess, '⁨my_model_final.ckpt⁩.data-00000-of-00001')\n",
    "#    for epoch in range(n_epochs):\n",
    "#        if epoch % 100 == 0: #checkpoint every 100 epochs\n",
    "            #save_path = saver.save(sess,\"⁨my_model.ckpt\")\n",
    "            \n",
    "#            sess.run(training_op)\n",
    "#    best_theta = theta.eval()\n",
    "    #save_path = saver.save(sess, \"⁨my_model_final.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Graph and Training Curves Using TensorBoard (Needs More Work)\n",
    "\n",
    "Need to ensure each we create a new log directory every time we run the model. For this purpose we will include the timestamp in name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d5H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run.{}\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14194155]\n",
      " [ 0.178478  ]\n",
      " [-0.3267207 ]\n",
      " [ 0.557111  ]\n",
      " [ 0.2079308 ]\n",
      " [-0.03617215]\n",
      " [ 0.6804452 ]\n",
      " [ 0.6969156 ]\n",
      " [ 0.6307759 ]]\n"
     ]
    }
   ],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0,1.0), name = \"theta\")\n",
    "init = tf.global_variables_initializer()\n",
    "#Need to add the following 2 lines at the end of our construction phase.\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0: #checkpoint every 100 epochs\n",
    "            \n",
    "            sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    #print(best_theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line creates a node in the graph that will evaluate the MSE value and write it to a TensorBoard compatible binary log string called summary.\n",
    "\n",
    "The second line creates a FileWriter that you will use to write summaries to logfiles in the log directory.\n",
    "\n",
    "---------------------(Will Come Back Later)-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity\n",
    "\n",
    "Suppose we want to create a graph that uses multiple ReLU components. \n",
    "\n",
    "Eqn of Relu:\n",
    "\n",
    "$h_{w,b}(X) = max(X.w + b, 0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"x\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name = \"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name = \"weights2\")\n",
    "b1 = tf.Variable(0.0, name = \"bias1\")\n",
    "b2 = tf.Variable(0.0, name = \"bias2\")\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name = \"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name = \"z2\")\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name = \"relu1\")\n",
    "relu2 = tf.maximum(z2, 0., name = \"relu2\")\n",
    "\n",
    "output = tf.add(relu1, relu2, name = \"output\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is repetitive. TensorFlow allows you to stay DRY (Don't Repeat Yourself). \n",
    "\n",
    "Create a function to build a ReLU. The following code creates five ReLUs and outputs their sum (note that add_n() creates an operation that will compute the sum of a list of tensors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    w_shape = (int(X.get_shape()[1]),1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name = \"weights\")\n",
    "    b = tf.Variable(0.0, name = \"bias\")\n",
    "    z = tf.add(tf.matmul(X,w), b, name = 'z')\n",
    "    return tf.maximum(z, 0., name = \"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"x\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name = \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you create a node, TensorFlow checks whether its name already exists and if it does appends an underscore followed by an index to make the name unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing Variables\n",
    "\n",
    "if you want to share a variable between different parts of a graph, one simple option is to create it first, then pass it as a parameter to functions that need it. \n",
    "\n",
    "For example, suppose you want to change the ReLU threshold from 0 using a shared threshold variable for all ReLUs, you can create that variable first and then pass it to the relu() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X, threshold):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]),1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name = \"weights\")\n",
    "        b = tf.Variable(0.0, name = \"bias\")\n",
    "        z = tf.add(tf.matmul(X,w), b, name = 'z')\n",
    "    return tf.maximum(z, threshold, name = \"max\")\n",
    "\n",
    "threshold = tf.Variable(0.0, name = \"threshold\")\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_features), name = \"X\")\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name = \"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?tf.name_scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code we assigned threshold separately from our ReLU function. We can also assign it within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        if not hasattr(relu, \"threshold\"):\n",
    "            relu.threshold = tf.Variable(0.0, name = \"threshold\")\n",
    "            w_shape = (int(X.get_shape()[1]),1)\n",
    "            w = tf.Variable(tf.random_normal(w_shape), name = \"weights\")\n",
    "            b = tf.Variable(0.0, name = \"bias\")\n",
    "            z = tf.add(tf.matmul(X,w), b, name = 'z')\n",
    "        return tf.maximum(z, relu.threshold, name = \"max\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?hasattr\n",
    "#Return whether the object has an attribute with the given name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
