# Affective Computing and Human-Robot Interaction

This is a report outlining the multi-modal emotion recognition system that was created for [COMP0053](http://www.cs.ucl.ac.uk/1819/a7p/t2/comp0053_affective_computing_and_human_robot_interaction/) module. 

Three modalities were assessed: heart-rate, voice, and galvanic skin response.

The main equipment used was the [empatica wrist sensor](https://www.empatica.com/research/e4/) which records electrodermal activities and heart rate changes. Macbook air's sound recording system was used to capture changes in voice response.

![empatica](https://www.empatica.com/assets/images/e4/e4_back-lg-hdpi.jpg)
![empatica2](https://www.empatica.com/assets/images/e4/solutions_image_2-lg-hdpi.jpg)

After the sensor data was collected, relevant features were extracted that could help classify the different stress levels faced by the subjects in this experiment.


## Additional Notes:

To get a broad overview of this field it is worth reading *Affective Computing* by Rosalind Picard.

![Rosaling](http://cognet.mit.edu/sites/default/files/styles/220width/public/9780262281584.jpg?itok=GjDvQ4Gz)

A shorter summary is also available [here.](https://affect.media.mit.edu/pdfs/95.picard.pdf)

For a more statistical and deep-learning treatment of this topic along with other application of the affectiva sensors visit the MIT publications page: 

https://www.media.mit.edu/groups/affective-computing/publications-list/

